{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mRcAC50VBqyE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hoKQ6Q-d1hG",
        "outputId": "ace2621b-2ecd-4101-d7ac-abb402d4d137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=f05be46c4e91486bf798387dd69a53d3dee0a164a6bd2db5019f52aafcc97279\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf spark-3.5.0-bin-hadoop3.tgz\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "LsmbtCVanyvx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTNSb9uun2Wn",
        "outputId": "94fac472-ea72-4093-b548-a4fa2f9bd2e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 400395283 Sep  9 02:10 spark-3.5.0-bin-hadoop3.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a3BQ0Y5CcQ87"
      },
      "outputs": [],
      "source": [
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FX_R1FINcfa9"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init(\"/content/spark-3.5.0-bin-hadoop3\")# SPARK_HOME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxlYztUJCf1r",
        "outputId": "58f99560-ae39-4df7-c611-d6546c9d86ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading amazon-us-customer-reviews-dataset.zip to /content\n",
            "100% 20.9G/21.0G [03:32<00:00, 163MB/s]\n",
            "100% 21.0G/21.0G [03:33<00:00, 105MB/s]\n"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"doinav\"\n",
        "os.environ['KAGGLE_KEY'] = \"0296dbba988a8d4ffdcd246d547d216a\"\n",
        "!kaggle datasets download -d cynthiarempel/amazon-us-customer-reviews-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KrW_hWxBBZ1",
        "outputId": "cbb5de6e-b23c-4e2d-cae8-a8e071dcad98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/amazon-us-customer-reviews-dataset.zip\n",
            "  inflating: amazon_reviews_us_Books_v1_02.tsv  \n"
          ]
        }
      ],
      "source": [
        "!unzip -j /content/amazon-us-customer-reviews-dataset.zip As _v1_02.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "7kY5sqtPHLiw",
        "outputId": "54b7d3c1-a31c-4b86-a9d6-fb4f4675c4a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fd0d4183640>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://fcf6d030a970:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Link Analysis</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql import Window\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "                    .appName(\"Link Analysis\") \\\n",
        "                    .getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni36v5A0aEo6"
      },
      "source": [
        "PAGE RANK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BhMAuE1PfLsr"
      },
      "outputs": [],
      "source": [
        "# Import the dataset as RDD and remove the header\n",
        "books = spark.sparkContext.textFile('amazon_reviews_us_Books_v1_02.tsv', minPartitions=8) # import as rdd dataset\n",
        "\n",
        "header = books.first()\n",
        "books = books.filter(lambda line: line != header)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xm7flWIbvzD5"
      },
      "outputs": [],
      "source": [
        "# Pre-process data by splitting the columns, retrieve column 1 (customer id) and column 2 (product id), sample 5% of it\n",
        "data = books.map(lambda x: (x.split('\\t')[1], x.split('\\t')[3])).sample(False, 0.05, 99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "D8dnlIAIDxI9"
      },
      "outputs": [],
      "source": [
        "# Group the data by costumer id -> map product ids into lists, and filter out customer ids having reviewed only one book\n",
        "df = data.groupByKey().mapValues(list)\n",
        "filtered = df.filter(lambda x: len(x[1]) > 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FA3aZVwgx0cX"
      },
      "outputs": [],
      "source": [
        "# Compute the total number of nodes (distinct book id)\n",
        "tot = data.map(lambda x: x[1]).distinct().count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eHkSDUmYor5U"
      },
      "outputs": [],
      "source": [
        "# Compute the edges between books\n",
        "def calculate_linkages(data):\n",
        "    key, values = data\n",
        "    combine = [(v1, v2) for i, v1 in enumerate(values) for v2 in values[i + 1:]]\n",
        "    add = [(v2, v1) for (v1, v2) in combine]\n",
        "    return (combine + add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HNsYkMmPgh2Y"
      },
      "outputs": [],
      "source": [
        "# Compute the list of edges\n",
        "links = filtered.map(lambda x: calculate_linkages(x)).flatMap(lambda value: value)\n",
        "\n",
        "# Calculate out-degree for each node\n",
        "id2degree = links.countByKey()\n",
        "\n",
        "# Sort the items in the defaultdict by key in descending order\n",
        "sorted_items = sorted(id2degree.items(), key=lambda x: x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SEXbr-RwIp3F"
      },
      "outputs": [],
      "source": [
        "# Create the transportation matrix and its transposed\n",
        "P = links.map(lambda x: (x[0], x[1], 1 / id2degree[x[0]])) #(i, j, Mij)\n",
        "PT = P.map(lambda x: (x[1], x[0], x[2])) #(j, i , Mij)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "oClLZQwfgGL8"
      },
      "outputs": [],
      "source": [
        "# Calculate the initial probability\n",
        "def calculate_probability(degrees, total):\n",
        "    prob = 1 / total\n",
        "    p_i = {item: prob for item in degrees.keys()}\n",
        "    return p_i\n",
        "\n",
        "p_i = calculate_probability(id2degree, tot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hzgmDlDwJYN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f090de35-4dcd-4e2f-962e-207c2a65de5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0\n",
            "iteration 1\n",
            "iteration 2\n",
            "iteration 3\n",
            "iteration 4\n",
            "iteration 5\n",
            "iteration 6\n",
            "iteration 7\n",
            "iteration 8\n",
            "iteration 9\n",
            "iteration 10\n",
            "iteration 11\n",
            "iteration 12\n",
            "iteration 13\n",
            "iteration 14\n",
            "iteration 15\n",
            "iteration 16\n",
            "iteration 17\n",
            "iteration 18\n",
            "iteration 19\n",
            "iteration 20\n",
            "iteration 21\n",
            "iteration 22\n",
            "iteration 23\n",
            "iteration 24\n",
            "iteration 25\n",
            "iteration 26\n",
            "iteration 27\n",
            "iteration 28\n",
            "iteration 29\n",
            "iteration 30\n",
            "iteration 31\n",
            "iteration 32\n",
            "iteration 33\n",
            "iteration 34\n",
            "iteration 35\n",
            "iteration 36\n",
            "iteration 37\n",
            "iteration 38\n",
            "iteration 39\n",
            "iteration 40\n",
            "iteration 41\n",
            "iteration 42\n",
            "iteration 43\n",
            "iteration 44\n",
            "iteration 45\n",
            "iteration 46\n",
            "iteration 47\n",
            "iteration 48\n",
            "iteration 49\n"
          ]
        }
      ],
      "source": [
        "# Exploit the power method for PageRank by iteratively updating the probabilities\n",
        "for i in range(50):\n",
        "    new_p = PT.map(lambda x:(x[0], (x[2]*p_i[x[1]])))\\\n",
        "              .reduceByKey(lambda x,y: x+y)\\\n",
        "              .collect()\\\n",
        "\n",
        "    for idx,prb in new_p:\n",
        "        p_i[idx] = prb\n",
        "\n",
        "    print(f\"iteration {i}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the results into a dictionary\n",
        "d = dict(new_p)\n",
        "\n",
        "# Sort it by product in ascending order\n",
        "sorted_d = dict(sorted(d.items(), key=lambda item: item[0], reverse=False))"
      ],
      "metadata": {
        "id": "2sZtuyUJlH0h"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcHbOPnPK1PQ",
        "outputId": "e97fb76d-2106-4ae1-b46e-4f83130ac48d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most quoted products:\n",
            "With prob: 0.00012314727975369468, you take product with code: 0385504209\n",
            "With prob: 8.926467652436924e-05, you take product with code: 0316769487\n",
            "With prob: 8.498383247184573e-05, you take product with code: 043935806X\n",
            "With prob: 7.58342347673823e-05, you take product with code: 0316666343\n",
            "With prob: 7.1874565024191e-05, you take product with code: 0446676098\n",
            "With prob: 6.92401985330735e-05, you take product with code: 0439139597\n",
            "With prob: 6.881467050514896e-05, you take product with code: 0375726403\n",
            "With prob: 6.620958344884291e-05, you take product with code: 0439136350\n",
            "With prob: 6.52873916655704e-05, you take product with code: 0446532231\n",
            "With prob: 6.34226928276526e-05, you take product with code: 1931561648\n",
            "With prob: 6.118308095938049e-05, you take product with code: 0671027360\n",
            "With prob: 6.0449845549312354e-05, you take product with code: 0525947647\n",
            "With prob: 6.005965346074745e-05, you take product with code: 0393317552\n",
            "With prob: 5.877529775868174e-05, you take product with code: 0671027387\n",
            "With prob: 5.8420103369226576e-05, you take product with code: 0618002219\n",
            "With prob: 5.6106594531544575e-05, you take product with code: 0590353403\n",
            "With prob: 5.489213027758119e-05, you take product with code: 0385512104\n",
            "With prob: 5.459846337574449e-05, you take product with code: 0446677450\n",
            "With prob: 5.4563792763222946e-05, you take product with code: 0385335482\n",
            "With prob: 5.2246219988014256e-05, you take product with code: 0399144463\n"
          ]
        }
      ],
      "source": [
        "# Sort and print the most recurrent products\n",
        "sorted_p_i = sorted(p_i.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "print('Most quoted products:')\n",
        "for item, prob in sorted_p_i:\n",
        "    print(f'With prob: {prob}, you take product with code: {item}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nli8jhV5x9x-"
      },
      "outputs": [],
      "source": [
        "# Define the list of values you want to filter on in column 3\n",
        "values_to_filter = []\n",
        "\n",
        "for index, (item, prob) in enumerate(sorted_p_i):\n",
        "    if index > 10:\n",
        "        break\n",
        "    values_to_filter.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXLZPsJD4qAq",
        "outputId": "505d2d93-cfc6-4052-9213-d81a80cc49e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('0385504209', 'The Da Vinci Code')]\n",
            "[('0316769487', 'The Catcher in the Rye')]\n",
            "[('043935806X', 'Harry Potter and the Order of the Phoenix (Book 5)')]\n",
            "[('0316666343', 'The Lovely Bones')]\n",
            "[('0446676098', 'The Notebook')]\n",
            "[('0439139597', 'Harry Potter And The Goblet Of Fire (Book 4)')]\n",
            "[('0375726403', 'Empire Falls')]\n",
            "[('0439136350', 'Harry Potter And The Prisoner Of Azkaban')]\n",
            "[('0446532231', \"Dude, Where's My Country?\")]\n",
            "[('1931561648', \"The Time Traveler's Wife\")]\n",
            "[('0671027360', 'Angels & Demons')]\n"
          ]
        }
      ],
      "source": [
        "# Show the first 10 products by page rank and associated title\n",
        "names = books.filter(lambda x: x.split('\\t')[3] in values_to_filter).map(lambda x: (x.split('\\t')[3], x.split('\\t')[5]))\n",
        "\n",
        "for i in values_to_filter:\n",
        "  name = names.filter(lambda x: x[0] == i)\n",
        "  print(name.take(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOPIC SENSITIVE PAGE RANK using book rankings"
      ],
      "metadata": {
        "id": "lzoFF3RviRAZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "k0T08vNdhWpy"
      },
      "outputs": [],
      "source": [
        "# The same dataset as before, now also containing the ratings for each reviewed product\n",
        "datats = books.map(lambda x: (x.split('\\t')[1], x.split('\\t')[3], x.split('\\t')[7])).sample(False, 0.05, 99)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by costumer id and map values into a list of tuples (product_id, rating)\n",
        "dfts = datats.groupBy(lambda x: x[0]).mapValues(lambda values: [(value[1], value[2]) for value in values])"
      ],
      "metadata": {
        "id": "nf7TImAsklbz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out dead ends\n",
        "filteredts = dfts.filter(lambda x: len(x[1]) > 1)"
      ],
      "metadata": {
        "id": "uokzkwtnkllX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From the filtered df retrieve the list of tuples (product_id, rating)\n",
        "S = filteredts.flatMap(lambda x: x[1])"
      ],
      "metadata": {
        "id": "Hum8DEwRklvY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wOuLiIh2UPQS"
      },
      "outputs": [],
      "source": [
        "# Compute the average rating per book\n",
        "# - Convert rating to int and create a count\n",
        "# - Sum ratings and count for each product\n",
        "# - Divide sum of ratings by count to get average\n",
        "average_ratings = S \\\n",
        "                  .map(lambda x: (x[0], (int(x[1]), 1))) \\\n",
        "                  .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
        "                  .mapValues(lambda x: round(float(x[0] / x[1]), 3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out nodes having a rating greater or equal to 4\n",
        "S_above3 = average_ratings.filter(lambda x: float(x[1]) >= 4)\n",
        "\n",
        "# Cardinality of the set of topic-sensitive products\n",
        "S_count_above3 = S_above3.count()"
      ],
      "metadata": {
        "id": "eCata3LO3Viv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the topic-sensitive vector: each book is assigned value 1 if the book is topic-sensitive, 0 otherwise\n",
        "e_S_above3 = average_ratings\\\n",
        "              .map(lambda x: int(float(x[1])>= 4))\\\n",
        "              .collect()"
      ],
      "metadata": {
        "id": "8eHTcJ9B4cwK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "pq-zLxKOiiyZ"
      },
      "outputs": [],
      "source": [
        "# Compute the Topic Sensitive PR for each item\n",
        "def TopicSensitivePR(d, e, beta, n):\n",
        "    TSPR = {}\n",
        "    for (key_pr, pagerank), element in zip(d.items(), e):\n",
        "      new_value = 0\n",
        "      new_value += beta * pagerank + (1 - beta) * element / n\n",
        "      TSPR[key_pr] = new_value\n",
        "    return TSPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "azeLlBK5ii1L"
      },
      "outputs": [],
      "source": [
        "beta = 0.8\n",
        "TSPR_above3 = TopicSensitivePR(sorted_d, e_S_above3, beta, S_count_above3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "AotMs-Tfii3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb53a7f-5b3c-46a0-b2e1-9e7178d6a958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most quoted products:\n",
            "With prob: 0.00010541961136593456, you take product with code: 0385504209\n",
            "With prob: 7.831352878247421e-05, you take product with code: 0316769487\n",
            "With prob: 6.798706597747659e-05, you take product with code: 043935806X\n",
            "With prob: 6.756917537688465e-05, you take product with code: 0316666343\n",
            "With prob: 6.440143958233162e-05, you take product with code: 0446676098\n",
            "With prob: 6.195352396709798e-05, you take product with code: 0375726403\n",
            "With prob: 5.986945432205314e-05, you take product with code: 0439136350\n",
            "With prob: 5.9131700895435136e-05, you take product with code: 0446532231\n",
            "With prob: 5.7639941825100895e-05, you take product with code: 1931561648\n",
            "With prob: 5.539215882645881e-05, you take product with code: 0439139597\n"
          ]
        }
      ],
      "source": [
        "#Sort and print the most recurrent products\n",
        "sorted_TSPR_above3= sorted(TSPR_above3.items(), key=lambda x:x[1], reverse = True)[:10]\n",
        "print('Most quoted products:')\n",
        "for item, prob in sorted_TSPR_above3:\n",
        "    print(f'With prob: {prob}, you take product with code: {item}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "iJfYU3lcktLD"
      },
      "outputs": [],
      "source": [
        "# Define the list of values you want to filter on in column 3\n",
        "values_to_filter = []\n",
        "for index, (item, prob) in enumerate(sorted_TSPR_above3):\n",
        "    if index > 10:\n",
        "        break\n",
        "    values_to_filter.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the books titles and ratings on book code\n",
        "names_TSPR_above3 = books.filter(lambda x: x.split('\\t')[3] in values_to_filter).map(lambda x: (x.split('\\t')[3], x.split('\\t')[5], x.split('\\t')[7])).distinct()\n",
        "join_above3 = names_TSPR_above3.join(average_ratings)"
      ],
      "metadata": {
        "id": "Q1Kzqvtd0oy4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "OHiH59XK4hqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17babfce-45dc-4322-e709-4ab38a82e898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('0385504209', ('The Da Vinci Code', 3.562))]\n",
            "[('0316769487', ('The Catcher in the Rye', 4.32))]\n",
            "[('043935806X', ('Harry Potter and the Order of the Phoenix (Book 5)', 4.324))]\n",
            "[('0316666343', ('The Lovely Bones', 3.692))]\n",
            "[('0446676098', ('The Notebook', 3.944))]\n",
            "[('0375726403', ('Empire Falls', 4.364))]\n",
            "[('0439136350', ('Harry Potter And The Prisoner Of Azkaban', 4.875))]\n",
            "[('0446532231', (\"Dude, Where's My Country?\", 4.118))]\n",
            "[('1931561648', (\"The Time Traveler's Wife\", 4.444))]\n",
            "[('0439139597', ('Harry Potter And The Goblet Of Fire (Book 4)', 4.6))]\n"
          ]
        }
      ],
      "source": [
        "# Show the resulting RDD, containing book code, title and average rating\n",
        "for i in values_to_filter:\n",
        "  name = join_above3.filter(lambda x: x[0] == i)\n",
        "  print(name.take(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "LZyoqbfdJEuY"
      },
      "outputs": [],
      "source": [
        "# Filter out nodes having a rating larger than 4\n",
        "S_less3 = average_ratings.filter(lambda x: int(x[1]) < 4)\n",
        "\n",
        "# Cardinality of the set of topic-sensitive products\n",
        "S_count_less3 = S_less3.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "6d0qh7hYJEyq"
      },
      "outputs": [],
      "source": [
        "# Compute the topic-sensitive vector: each book is assigned value 1 if the book is topic-sensitive, 0 otherwise\n",
        "e_S_less3 = average_ratings\\\n",
        "              .map(lambda x: int(int(x[1])< 4))\\\n",
        "              .collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ugS5pQfpJE5T"
      },
      "outputs": [],
      "source": [
        "TSPR_less3 = TopicSensitivePR(d, e_S_less3, beta, S_count_less3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "39y-lqqCJE8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05cdb710-73ff-4526-e826-18b2c178d622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most quoted products:\n",
            "With prob: 0.00012370356867136024, you take product with code: 0385504209\n",
            "With prob: 8.585313268231032e-05, you take product with code: 0316666343\n",
            "With prob: 8.268539688775729e-05, you take product with code: 0446676098\n",
            "With prob: 7.413220963590887e-05, you take product with code: 0671027360\n",
            "With prob: 7.141174121949539e-05, you take product with code: 0316769487\n",
            "With prob: 6.886451556900007e-05, you take product with code: 0446677450\n",
            "With prob: 6.798706597747659e-05, you take product with code: 043935806X\n",
            "With prob: 6.698272085881588e-05, you take product with code: 0399144463\n",
            "With prob: 6.690861564040776e-05, you take product with code: 0060392452\n",
            "With prob: 6.63062405431688e-05, you take product with code: 1592400876\n"
          ]
        }
      ],
      "source": [
        "#Sort and print the most recurrent products\n",
        "sorted_TSPR_less3= sorted(TSPR_less3.items(), key=lambda x:x[1], reverse = True)[:10]\n",
        "print('Most quoted products:')\n",
        "for item, prob in sorted_TSPR_less3:\n",
        "    print(f'With prob: {prob}, you take product with code: {item}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SM9TJmj_JE-_"
      },
      "outputs": [],
      "source": [
        "# Define the list of values you want to filter on in column 3\n",
        "values_to_filter = []\n",
        "for index, (item, prob) in enumerate(sorted_TSPR_less3):\n",
        "    if index > 10:\n",
        "        break\n",
        "    values_to_filter.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the code and book name with the average rating\n",
        "names_TSPR_less3 = books.filter(lambda x: x.split('\\t')[3] in values_to_filter).map(lambda x: (x.split('\\t')[3], x.split('\\t')[5])).distinct()\n",
        "join_less3 = names_TSPR_less3.join(average_ratings)"
      ],
      "metadata": {
        "id": "_NjlfFeVtO6F"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "XoORgq3lJFBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d62078ca-93be-4d15-fd85-2562737f67a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('0385504209', ('The Da Vinci Code', 3.562))]\n",
            "[('0316666343', ('The Lovely Bones', 3.692))]\n",
            "[('0446676098', ('The Notebook', 3.944))]\n",
            "[('0671027360', ('Angels & Demons', 3.643))]\n",
            "[('0316769487', ('The Catcher in the Rye', 4.32))]\n",
            "[('0446677450', ('Rich Dad, Poor Dad: What the Rich Teach Their Kids About Money--That the Poor and Middle Class Do Not!', 3.857))]\n",
            "[('043935806X', ('Harry Potter and the Order of the Phoenix (Book 5)', 4.324))]\n",
            "[('0399144463', ('Who Moved My Cheese?: An Amazing Way to Deal with Change in Your Work and in Your Life', 3.143))]\n",
            "[('0060392452', ('Stupid White Men ...And Other Sorry Excuses for the State of the Nation!', 3.364))]\n",
            "[('1592400876', ('Eats, Shoots & Leaves: The Zero Tolerance Approach to Punctuation', 3.778))]\n"
          ]
        }
      ],
      "source": [
        "# Show the resulting RDD, containing book code, title and average rating\n",
        "for i in values_to_filter:\n",
        "  name = join_less3.filter(lambda x: x[0] == i)\n",
        "  print(name.take(1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}