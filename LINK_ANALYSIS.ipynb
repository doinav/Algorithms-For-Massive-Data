{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doinav/Algorithms-For-Massive-Data/blob/main/LINK_ANALYSIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mRcAC50VBqyE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8hoKQ6Q-d1hG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40bb3f24-e686-4313-93d3-b115d21b893a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=1a59bb10b4ead5629582922cb9f81e9c7bc64abab654c591db1d34caf626db7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LsmbtCVanyvx"
      },
      "outputs": [],
      "source": [
        "!rm -rf spark-3.5.0-bin-hadoop3.tgz\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kTNSb9uun2Wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa7e1e0b-80c4-4f0c-dd0a-3bf3ca515912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 400395283 Sep  9 02:10 spark-3.5.0-bin-hadoop3.tgz\n"
          ]
        }
      ],
      "source": [
        "!ls -l spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a3BQ0Y5CcQ87"
      },
      "outputs": [],
      "source": [
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FX_R1FINcfa9"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init(\"/content/spark-3.5.0-bin-hadoop3\") #SPARK_HOME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dxlYztUJCf1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56155208-e073-49b8-c0f3-d307be107a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading amazon-us-customer-reviews-dataset.zip to /content\n",
            "100% 20.9G/21.0G [03:41<00:00, 159MB/s]\n",
            "100% 21.0G/21.0G [03:41<00:00, 102MB/s]\n"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"doinav\"\n",
        "os.environ['KAGGLE_KEY'] = \"******\"\n",
        "!kaggle datasets download -d cynthiarempel/amazon-us-customer-reviews-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5KrW_hWxBBZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3b4ab0-7aa6-4d09-b762-07d4a6e92537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/amazon-us-customer-reviews-dataset.zip\n",
            "  inflating: amazon_reviews_us_Books_v1_02.tsv  \n"
          ]
        }
      ],
      "source": [
        "!unzip -j /content/amazon-us-customer-reviews-dataset.zip amazon_reviews_us_Books_v1_02.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7kY5sqtPHLiw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "7094988f-b7a2-47b7-b3f0-ef60fb906b02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78fcd4230640>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://1d504a48567d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Link Analysis</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql import Window\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "                    .appName(\"Link Analysis\") \\\n",
        "                    .getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BhMAuE1PfLsr"
      },
      "outputs": [],
      "source": [
        "# Import the dataset as RDD and remove the header\n",
        "books = spark.sparkContext.textFile('amazon_reviews_us_Books_v1_02.tsv', minPartitions=8) # import as rdd dataset\n",
        "\n",
        "header = books.first()\n",
        "books = books.filter(lambda line: line != header)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xm7flWIbvzD5"
      },
      "outputs": [],
      "source": [
        "# Pre-process data by splitting the columns, retrieve column 1 (customer id) and column 2 (product id), sample 10% of it\n",
        "data = books.map(lambda x: (x.split('\\t')[1], x.split('\\t')[3])).sample(False, 0.1, 125)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of rows in the sampled df\n",
        "data.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVEXfPSD8zRG",
        "outputId": "676a1780-d486-40f1-85ca-0a8bd0d5e6ec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "309998"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D8dnlIAIDxI9"
      },
      "outputs": [],
      "source": [
        "# Group the data by costumer id -> map product ids into lists, and filter out customer ids having reviewed only one book\n",
        "df = data.groupByKey().mapValues(list)\n",
        "filtered = df.filter(lambda x: len(x[1]) > 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FA3aZVwgx0cX"
      },
      "outputs": [],
      "source": [
        "# Compute the total number of nodes (distinct book id)\n",
        "tot = data.map(lambda x: x[1]).distinct().count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eHkSDUmYor5U"
      },
      "outputs": [],
      "source": [
        "# Compute the edges between books\n",
        "def calculate_linkages(data):\n",
        "    key, values = data\n",
        "    combine = [(v1, v2) for i, v1 in enumerate(values) for v2 in values[i + 1:]]\n",
        "    add = [(v2, v1) for (v1, v2) in combine]\n",
        "    return (combine + add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HNsYkMmPgh2Y"
      },
      "outputs": [],
      "source": [
        "# Compute the list of edges\n",
        "links = filtered.map(lambda x: calculate_linkages(x)).flatMap(lambda value: value)\n",
        "\n",
        "# Calculate out-degree for each node\n",
        "id2degree = links.countByKey()\n",
        "\n",
        "# Sort the items in the defaultdict by key in descending order\n",
        "sorted_items = sorted(id2degree.items(), key=lambda x: x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SEXbr-RwIp3F"
      },
      "outputs": [],
      "source": [
        "# Create the transportation matrix and its transposed\n",
        "P = links.map(lambda x: (x[0], x[1], 1 / id2degree[x[0]])) #(i, j, Mij)\n",
        "PT = P.map(lambda x: (x[1], x[0], x[2])) #(j, i , Mij)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oClLZQwfgGL8"
      },
      "outputs": [],
      "source": [
        "# Calculate the initial probability\n",
        "def calculate_probability(degrees, total):\n",
        "    prob = 1 / total\n",
        "    p_i = {item: prob for item in degrees.keys()}\n",
        "    return p_i\n",
        "\n",
        "p_i = calculate_probability(id2degree, tot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hzgmDlDwJYN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46a6e97-8188-4a81-be9d-eed0c9915fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0\n",
            "iteration 1\n",
            "iteration 2\n",
            "iteration 3\n",
            "iteration 4\n",
            "iteration 5\n",
            "iteration 6\n",
            "iteration 7\n",
            "iteration 8\n",
            "iteration 9\n",
            "iteration 10\n",
            "iteration 11\n",
            "iteration 12\n",
            "iteration 13\n",
            "iteration 14\n",
            "iteration 15\n",
            "iteration 16\n",
            "iteration 17\n",
            "iteration 18\n",
            "iteration 19\n",
            "iteration 20\n",
            "iteration 21\n",
            "iteration 22\n",
            "iteration 23\n",
            "iteration 24\n",
            "iteration 25\n",
            "iteration 26\n",
            "iteration 27\n",
            "iteration 28\n",
            "iteration 29\n",
            "iteration 30\n",
            "iteration 31\n",
            "iteration 32\n",
            "iteration 33\n",
            "iteration 34\n",
            "iteration 35\n",
            "iteration 36\n",
            "iteration 37\n",
            "iteration 38\n",
            "iteration 39\n",
            "iteration 40\n",
            "iteration 41\n",
            "iteration 42\n",
            "iteration 43\n",
            "iteration 44\n",
            "iteration 45\n",
            "iteration 46\n",
            "iteration 47\n",
            "iteration 48\n",
            "iteration 49\n"
          ]
        }
      ],
      "source": [
        "# Exploit the power method for PageRank by iteratively updating the probabilities\n",
        "for i in range(50):\n",
        "    new_p = PT.map(lambda x:(x[0], (x[2]*p_i[x[1]])))\\\n",
        "              .reduceByKey(lambda x,y: x+y)\\\n",
        "              .collect()\\\n",
        "\n",
        "    for idx,prb in new_p:\n",
        "        p_i[idx] = prb\n",
        "\n",
        "    print(f\"iteration {i}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2sZtuyUJlH0h"
      },
      "outputs": [],
      "source": [
        "# Save the results into a dictionary\n",
        "d = dict(new_p)\n",
        "\n",
        "# Sort it by product in ascending order\n",
        "sorted_d = dict(sorted(d.items(), key=lambda item: item[0], reverse=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HcHbOPnPK1PQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f12f27-7b67-42f5-feef-44a7af528d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most quoted products:\n",
            "With prob: 0.00011288455081260919, you take product with code: 0373250517\n",
            "With prob: 0.0001063244794487078, you take product with code: 0345458931\n",
            "With prob: 0.00010014309221280358, you take product with code: 0399152180\n",
            "With prob: 8.79062811490297e-05, you take product with code: 0385504209\n",
            "With prob: 8.46592070356197e-05, you take product with code: 0385336675\n",
            "With prob: 8.234647965291267e-05, you take product with code: 0385333927\n",
            "With prob: 8.138651979442579e-05, you take product with code: 043935806X\n",
            "With prob: 8.043795194239667e-05, you take product with code: 0767908171\n",
            "With prob: 7.940514697075e-05, you take product with code: 0312252617\n",
            "With prob: 7.871454788775515e-05, you take product with code: 0451524934\n",
            "With prob: 7.812703171011327e-05, you take product with code: 0375826688\n",
            "With prob: 7.753878908295939e-05, you take product with code: 0684801221\n",
            "With prob: 7.664525046212533e-05, you take product with code: 0316769487\n",
            "With prob: 7.596632953785859e-05, you take product with code: 039914563X\n",
            "With prob: 7.590961492207544e-05, you take product with code: 031299866X\n",
            "With prob: 7.581242555583714e-05, you take product with code: 0060004762\n",
            "With prob: 7.581242555583714e-05, you take product with code: 0345468104\n",
            "With prob: 7.581242555583714e-05, you take product with code: 0345410971\n",
            "With prob: 7.513175343639266e-05, you take product with code: 0060562366\n",
            "With prob: 7.459026156028531e-05, you take product with code: 0871138646\n"
          ]
        }
      ],
      "source": [
        "# Sort and print the most recurrent products\n",
        "sorted_p_i = sorted(p_i.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "print('Most quoted products:')\n",
        "for item, prob in sorted_p_i:\n",
        "    print(f'With prob: {prob}, you take product with code: {item}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nli8jhV5x9x-"
      },
      "outputs": [],
      "source": [
        "# Define the list of values you want to filter on in column 3\n",
        "values_to_filter = []\n",
        "\n",
        "for index, (item, prob) in enumerate(sorted_p_i):\n",
        "    if index > 10:\n",
        "        break\n",
        "    values_to_filter.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AXLZPsJD4qAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98255a44-b832-4b1b-f0ed-2682da73f5bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('0373250517', 'Spitting Feathers (Red Dress Ink)')]\n",
            "[('0345458931', 'Body Double')]\n",
            "[('0399152180', 'Melancholy Baby (A Sunny Randall Novel)')]\n",
            "[('0385504209', 'The Da Vinci Code')]\n",
            "[('0385336675', 'The Enemy (Jack Reacher, No. 8)')]\n",
            "[('0385333927', 'Pagan Babies')]\n",
            "[('043935806X', 'Harry Potter and the Order of the Phoenix (Book 5)')]\n",
            "[('0767908171', 'A Short History of Nearly Everything')]\n",
            "[('0312252617', 'Fast Women')]\n",
            "[('0451524934', '1984 (Signet Classics)')]\n",
            "[('0375826688', 'Eragon (Inheritance)')]\n"
          ]
        }
      ],
      "source": [
        "# Show the first 10 products by page rank and associated title\n",
        "names = books.filter(lambda x: x.split('\\t')[3] in values_to_filter).map(lambda x: (x.split('\\t')[3], x.split('\\t')[5]))\n",
        "\n",
        "for i in values_to_filter:\n",
        "  name = names.filter(lambda x: x[0] == i)\n",
        "  print(name.take(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzoFF3RviRAZ"
      },
      "source": [
        "TOPIC SENSITIVE PAGE RANK using book rankings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "k0T08vNdhWpy"
      },
      "outputs": [],
      "source": [
        "# The same dataset as before, now also containing the ratings for each reviewed product\n",
        "datats = books.map(lambda x: (x.split('\\t')[1], x.split('\\t')[3], x.split('\\t')[7])).sample(False, 0.1, 125)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nf7TImAsklbz"
      },
      "outputs": [],
      "source": [
        "# Group the data by costumer id and map values into a list of tuples (product_id, rating)\n",
        "dfts = datats.groupBy(lambda x: x[0]).mapValues(lambda values: [(value[1], value[2]) for value in values])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "uokzkwtnkllX"
      },
      "outputs": [],
      "source": [
        "# Filter out dead ends\n",
        "filteredts = dfts.filter(lambda x: len(x[1]) > 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Hum8DEwRklvY"
      },
      "outputs": [],
      "source": [
        "# From the filtered df retrieve the list of tuples (product_id, rating)\n",
        "S = filteredts.flatMap(lambda x: x[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wOuLiIh2UPQS"
      },
      "outputs": [],
      "source": [
        "# Compute the average rating per book\n",
        "# - Convert rating to int and create a count\n",
        "# - Sum ratings and count for each product\n",
        "# - Divide sum of ratings by count to get average\n",
        "average_ratings = S \\\n",
        "                  .map(lambda x: (x[0], (int(x[1]), 1))) \\\n",
        "                  .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
        "                  .mapValues(lambda x: round(float(x[0] / x[1]), 3)) \\\n",
        "                  .sortBy(lambda x: x[0], ascending = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "eCata3LO3Viv"
      },
      "outputs": [],
      "source": [
        "# Filter out nodes having a rating greater or equal to 4\n",
        "S_above3 = average_ratings.filter(lambda x: float(x[1]) >= 4)\n",
        "# Cardinality of the set of topic-sensitive products\n",
        "S_count_above3 = S_above3.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8eHTcJ9B4cwK"
      },
      "outputs": [],
      "source": [
        "# Compute the topic-sensitive vector: each book is assigned value 1 if the book is topic-sensitive, 0 otherwise\n",
        "e_S_above3 = average_ratings\\\n",
        "              .map(lambda x: int(float(x[1])>= 4))\\\n",
        "              .collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "pq-zLxKOiiyZ"
      },
      "outputs": [],
      "source": [
        "# Compute the Topic Sensitive PR for each item\n",
        "def TopicSensitivePR(d, e, n):\n",
        "    TSPR = {}\n",
        "    beta = 0.8 #0.6\n",
        "    for (key_pr, pagerank), element in zip(d.items(), e):\n",
        "      new_value = 0\n",
        "      new_value += beta * pagerank + (1 - beta) * element / n\n",
        "      TSPR[key_pr] = new_value\n",
        "    return TSPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "azeLlBK5ii1L"
      },
      "outputs": [],
      "source": [
        "TSPR_above3 = TopicSensitivePR(sorted_d, e_S_above3, S_count_above3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "AotMs-Tfii3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c75688b-59d2-4de9-b269-da55b5ff6eff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most quoted products:\n",
            "With prob: 9.35242641603886e-05, you take product with code: 0373250517\n",
            "With prob: 8.827620706926749e-05, you take product with code: 0345458931\n",
            "With prob: 8.333109728054411e-05, you take product with code: 0399152180\n",
            "With prob: 7.094398913879701e-05, you take product with code: 0385336675\n",
            "With prob: 7.032502491922376e-05, you take product with code: 0385504209\n",
            "With prob: 6.832583934584187e-05, you take product with code: 043935806X\n",
            "With prob: 6.756698506421859e-05, you take product with code: 0767908171\n",
            "With prob: 6.674074108690124e-05, you take product with code: 0312252617\n",
            "With prob: 6.618826182050536e-05, you take product with code: 0451524934\n",
            "With prob: 6.587718372233013e-05, you take product with code: 0385333927\n"
          ]
        }
      ],
      "source": [
        "#Sort and print the most recurrent products\n",
        "sorted_TSPR_above3= sorted(TSPR_above3.items(), key=lambda x:x[1], reverse = True)[:10]\n",
        "print('Most quoted products:')\n",
        "for item, prob in sorted_TSPR_above3:\n",
        "    print(f'With prob: {prob}, you take product with code: {item}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iJfYU3lcktLD"
      },
      "outputs": [],
      "source": [
        "# Define the list of values you want to filter on in column 3\n",
        "values_to_filter = []\n",
        "for index, (item, prob) in enumerate(sorted_TSPR_above3):\n",
        "    if index > 10:\n",
        "        break\n",
        "    values_to_filter.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Q1Kzqvtd0oy4"
      },
      "outputs": [],
      "source": [
        "# Join the books titles and ratings on book code\n",
        "names_TSPR_above3 = books.filter(lambda x: x.split('\\t')[3] in values_to_filter).map(lambda x: (x.split('\\t')[3], x.split('\\t')[5], x.split('\\t')[7])).distinct()\n",
        "join_above3 = names_TSPR_above3.join(average_ratings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "OHiH59XK4hqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956a8705-520d-4d8f-827d-764785b8b331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('0373250517', ('Spitting Feathers (Red Dress Ink)', 5.0))]\n",
            "[('0345458931', ('Body Double', 4.167))]\n",
            "[('0399152180', ('Melancholy Baby (A Sunny Randall Novel)', 4.0))]\n",
            "[('0385336675', ('The Enemy (Jack Reacher, No. 8)', 4.429))]\n",
            "[('0385504209', ('The Da Vinci Code', 3.841))]\n",
            "[('043935806X', ('Harry Potter and the Order of the Phoenix (Book 5)', 4.464))]\n",
            "[('0767908171', ('A Short History of Nearly Everything', 4.706))]\n",
            "[('0312252617', ('Fast Women', 4.6))]\n",
            "[('0451524934', ('1984 (Signet Classics)', 4.794))]\n",
            "[('0385333927', ('Pagan Babies', 3.625))]\n"
          ]
        }
      ],
      "source": [
        "# Show the resulting RDD, containing book code, title and average rating\n",
        "for i in values_to_filter:\n",
        "  name = join_above3.filter(lambda x: x[0] == i)\n",
        "  print(name.take(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LZyoqbfdJEuY"
      },
      "outputs": [],
      "source": [
        "# Filter out nodes having a rating larger than 4\n",
        "S_less4 = average_ratings.filter(lambda x: int(x[1]) < 4)\n",
        "\n",
        "# Cardinality of the set of topic-sensitive products\n",
        "S_count_less4 = S_less4.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "6d0qh7hYJEyq"
      },
      "outputs": [],
      "source": [
        "# Compute the topic-sensitive vector: each book is assigned value 1 if the book is topic-sensitive, 0 otherwise\n",
        "e_S_less4 = average_ratings\\\n",
        "              .map(lambda x: int(int(x[1]) <= 3))\\\n",
        "              .collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ugS5pQfpJE5T"
      },
      "outputs": [],
      "source": [
        "TSPR_less4 = TopicSensitivePR(sorted_d, e_S_less4, S_count_less4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "39y-lqqCJE8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f449bcb2-7942-41eb-d1b4-20226306e788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most quoted products:\n",
            "With prob: 9.030764065008736e-05, you take product with code: 0373250517\n",
            "With prob: 8.505958355896625e-05, you take product with code: 0345458931\n",
            "With prob: 8.188171046181015e-05, you take product with code: 0385504209\n",
            "With prob: 8.011447377024287e-05, you take product with code: 0399152180\n",
            "With prob: 7.743386926491652e-05, you take product with code: 0385333927\n",
            "With prob: 7.4058310910677e-05, you take product with code: 0375826688\n",
            "With prob: 7.232974917287325e-05, you take product with code: 039914563X\n",
            "With prob: 7.122889479081463e-05, you take product with code: 0871138646\n",
            "With prob: 6.772736562849577e-05, you take product with code: 0385336675\n",
            "With prob: 6.686930175456411e-05, you take product with code: 0312873441\n"
          ]
        }
      ],
      "source": [
        "#Sort and print the most recurrent products\n",
        "sorted_TSPR_less4 = sorted(TSPR_less4.items(), key=lambda x:x[1], reverse = True)[:10]\n",
        "print('Most quoted products:')\n",
        "for item, prob in sorted_TSPR_less4:\n",
        "    print(f'With prob: {prob}, you take product with code: {item}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "SM9TJmj_JE-_"
      },
      "outputs": [],
      "source": [
        "# Define the list of values you want to filter on in column 3\n",
        "values_to_filter = []\n",
        "for index, (item, prob) in enumerate(sorted_TSPR_less4):\n",
        "    if index > 10:\n",
        "        break\n",
        "    values_to_filter.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "_NjlfFeVtO6F"
      },
      "outputs": [],
      "source": [
        "# Join the code and book name with the average rating\n",
        "names_TSPR_less4 = books.filter(lambda x: x.split('\\t')[3] in values_to_filter).map(lambda x: (x.split('\\t')[3], x.split('\\t')[5])).distinct()\n",
        "join_less4 = names_TSPR_less4.join(average_ratings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "XoORgq3lJFBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd608522-2760-452e-a83a-c42a73790df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('0373250517', ('Spitting Feathers (Red Dress Ink)', 5.0))]\n",
            "[('0345458931', ('Body Double', 4.167))]\n",
            "[('0385504209', ('The Da Vinci Code', 3.841))]\n",
            "[('0399152180', ('Melancholy Baby (A Sunny Randall Novel)', 4.0))]\n",
            "[('0385333927', ('Pagan Babies', 3.625))]\n",
            "[('0375826688', ('Eragon (Inheritance)', 3.708))]\n",
            "[('039914563X', ('The Bear and the Dragon', 2.2))]\n",
            "[('0871138646', ('Old Flames', 3.5))]\n",
            "[('0385336675', ('The Enemy (Jack Reacher, No. 8)', 4.429))]\n",
            "[('0312873441', ('Running On Instinct', 3.5))]\n"
          ]
        }
      ],
      "source": [
        "# Show the resulting RDD, containing book code, title and average rating\n",
        "for i in values_to_filter:\n",
        "  name = join_less4.filter(lambda x: x[0] == i)\n",
        "  print(name.take(1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1m_4YDSBbLUbdiKQVwceNbKI1gZXb7oRA",
      "authorship_tag": "ABX9TyOhGDs3npoJ69kgrytdwAes",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}